对表面上开源的LLM模型的开放性进行评估发现，很少有模型能够达到所声称的开放性
社交媒体和广告技术公司Meta最近发布了其大型语言模型Llama的更新。Llama 2以开源形式发布，使用户可以访问模型的权重、评估代码和文档。Meta表示，开源发布旨在使该模型“对个人、创作者、研究人员和企业可访问，以便他们可以负责任地进行实验、创新和扩展他们的想法。”

然而，与其他开源LLM和开源软件包相比，Llama 2相对封闭。尽管Meta已经提供了训练模型，但它并未分享模型的训练数据或用于训练的代码。虽然第三方可以创建扩展基础模型的应用程序，但有志于开发者和研究人员对模型进行深入分析的能力有限。

在荷兰尼姆根的拉德堡德大学的一组人工智能研究人员在ACM会议上提出的研究中，他们认为Llama 2并不是唯一一个被质疑为“开源”的LLM。在论文中，科学家们提出了一个多维度的模型开放性评估方法。他们使用这个评估标准对15个名义上开源的LLM在可用性、文档化程度和访问方法等方面进行评分。研究人员将这些评估结果收集在一个在线表格中，并已经扩展到包括21个不同的开源模型。如果小型的以研究为重点的模型被认为是“开放的、有足够的文档支持，并且在开源许可下发布”，它们也会被纳入评估范围，正如预印本中所述。
“Meta使用‘开源’这个词实在是误导人。” —Mark Dingemanse, Radboud大学

科学家们在寻找用于自己教学和研究的AI模型时开始了这个项目。 "如果你写一篇研究论文，你希望结果能够尽可能地可复制，" Radboud大学助理教授之一、该预印本的作者之一Andreas Liesenfeld说道。 "如果你使用这些技术进行研究，这是你特别看重的东西，对吧？这是我们没有从ChatGPT中看到的，比如，ChatGPT是基于OpenAI的生成预训练转换器（GPT）LLM系列构建的聊天机器人界面。尽管从其名称中可能推断出的情况与此不同，但OpenAI在今年早些时候推出GPT-4并获得微软的大量投资后，关闭了对其大部分研究代码的访问权限。"
事实上，OpenAI的ChatGPT模型在团队的公开度评估表中得分最低。在可用的状态中，包括公开、部分公开和关闭，除了“模型卡片”（一种描述模型及其限制的标准格式）和“预印本”（是否有关于该模型的深入研究论文）之外，ChatGPT在所有评估中都被标记为“关闭”。对于这两个状态，ChatGPT只获得“部分公开”的评级。Llama 2在整体上排名第二差，其整体公开度仅略好于ChatGPT。
AI的可复现性问题
Liesenfeld对基于ChatGPT的研究的可重复性的担忧已经得到了一些证据支持。斯坦福大学和加州大学伯克利分校的科学家们最近发表的一篇预印本表明，今年3月至6月间，GPT-4和GPT-3.5在推理任务上的表现发生了变化，大多数情况下是变差了。这些变化发生时，OpenAI并没有发布任何相关公告。这样的变化可能会阻止在那段时间内使用这些模型产生的任何研究结果的复制。

虽然Liesenfeld和他们的同事确定了几个更加开放的小型研究模型，比如Llama 2或ChatGPT，但他们发现所有他们评估的模型在两个关键方面都是封闭的。首先，很少有模型提供足够详细的现代LLM功能所需的重要细化过程，也就是人类反馈强化学习（RLHF）。这一关键步骤可以调整语言模型，使其在模型预训练期间训练的统计模式中产生有用的输出，似乎是当代LLM性能的秘密武器。这个过程需要大量的人力投入，在训练过程中对模型输出进行人为评估。

研究人员指出的第二个主要问题是商业LLM发布方式避开了同行评审过程。在学术研究中，通过经过同行评审的会议或期刊发布模型架构、训练方法和性能是一种成熟的做法，但ChatGPT和Llama 2只通过公司托管的预印本文件发布，很可能是为了保护模型结构和训练的商业机密细节。

虽然这个项目所展示的LLMs的可变开放性可能会推动该领域朝着真正的开源模型开发的方向发展，但Liesenfeld和他的同事们对学术研究中商业模型的使用仍持谨慎态度。本报告的合著者之一Mark Dingemanse对Llama 2模型有着特别强烈的评价：“将‘开源’这个词用于此实际上是误导性的：没有任何源代码可见，训练数据完全没有记录，除了光鲜亮丽的图表外，技术文档实际上相当糟糕。我们不知道为什么Meta如此热衷于让每个人都使用这个模型，但这家公司的选择历史并没有给人以信心。用户要小心。”
